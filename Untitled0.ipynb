{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLuLchdMlcctnoaWcSFIu9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zgres/car_data/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCtXVJA7NMnE"
      },
      "outputs": [],
      "source": [
        "# Устанавливаем OpenJDK\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Закачиваем Spark\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop2.7.tgz -O spark.tgz\n",
        "# Распаковываем архив со Spark\n",
        "!tar xf spark.tgz\n",
        "# Устанавливаем пакет findspark для работы со Spark из Python\n",
        "!pip install -q findspark\n",
        "# Настраиваем переменные окружения для работы с Apache Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop2.7\"\n",
        "# Находим установку Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "# Подключаем необходимые модули для работы со Spark из Python\n",
        "from pyspark.sql import SparkSession\n",
        "# Создаем сессию Spark на локальном компьютере\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip -O /content/ml-100k.zip -q\n",
        "!unzip -qq /content/ml-100k.zip -d \"sample_data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 1"
      ],
      "metadata": {
        "id": "ykTVARdSN7GM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модернизируйте заготовку заменив все участки <put your code here> на ваш код для того, что бы:\n",
        "* вычислять и выводить на экран статистику по числу оценок для каждого фильма\n",
        "* вычислять и выводить на экран статистику по числу оценок для всех фильмов"
      ],
      "metadata": {
        "id": "P8zVieFRN8mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Статистика для каждого фильма:"
      ],
      "metadata": {
        "id": "LhUXzHiCOIk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "rdd = spark.sparkContext.textFile(\"/content/sample_data/ml-100k/u.data\")\n",
        "#<put your code here>\n",
        "\n",
        "def printStat(inp):\n",
        "#<put your code here>\n",
        "\n",
        "print(f'Marks for film {ind}: 1 -> {marks[0]}, 2 -> {marks[1]}, 3 -> {marks[2]}, 4 -> {marks[3]}, 5 -> {marks[4]}')\n",
        "for i in aggPairRDD.mapValues(lambda x: dict(collections.Counter(x))).collect():\n",
        "printStat(i)"
      ],
      "metadata": {
        "id": "GSRRDX66OJrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 2"
      ],
      "metadata": {
        "id": "GFBIq2OhOW8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Произведите подсчёт частоты встречаемости слов с использованием ApacheSpark RDD. Ячейка ниже скачивает текст. Вам\n",
        "требуется:\n",
        "* Очистить текст от знаков препинания и пустых строк\n",
        "* Перевести в нижний регистр и разделить по пробелам\n",
        "* Подсчитать наиболее часто встречающиеся символы\n",
        "* Использовать RDD"
      ],
      "metadata": {
        "id": "v0hU8jeROZ3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример вывода:\n"
      ],
      "metadata": {
        "id": "jFEeR8FrOiub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.lib.ru/INOOLD/BALZAK/shagren.txt_Ascii.txt | iconv -f cp1251\n",
        "i = 0\n",
        "with open('/content/shagren.txt_Ascii.txt', encoding=\"cp1251\") as inF, open('/content/shagren.txt_utf8.txt', \"w\") as outF:\n",
        "  for line in inF:\n",
        "    outF.write(line)"
      ],
      "metadata": {
        "id": "3EYxU16tOouS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}